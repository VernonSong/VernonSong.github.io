---
typora-root-url: /Users/songweinan/Desktop/github/blog
---

tensorflow

底层 细粒度

声明式编程 解耦 



硬件层，支持各种高性能硬件。不同于简单使用CUDA Runtime API的其他平台，Google的工程师基于CUDA Driver API实现了控制粒度更细、并行性能更优的StreamExecutor 异构计算库，并对cuBLAS、cuDNN等库的函数变种进行了精确的适配。在推理态，尽管Google没有开源或销售TPU,然而TensorFlow开放性的设计已经
促使多家芯片厂家实现了对接，这为定制化设备上的计算性能提升提供了保障。针对高性能计算环境中常用的InfiniBand、RoCE等高速网络设备，以及NVLink等片间高速互联技术，TensorFlow 引人了RDMA、NCCL等协议，较好地解决了通信延迟问题，推进了分布式计算作业的加速比提升。



系统层 XLA 融合了编译器设计理论的油画框架，在数据流图运行过程中实时创建二进制代码，将其中大量细粒度的操作融合为少量粗粒度的专用核函数，减少途中操作执行时的内存分配和上下文切换开销，极大提升计算速度。通信模块设计，语法树优化



算法层，每种算法多种实现



平台设计模式

库模式 numpy等 灵活

框架模式 hadoop等 只需写业务逻辑密切相关的算法代码，不必关心运行机制的复杂性，灵活性受框架约束



TensorFlow的设计采用了库模式。 之所以如此，是出于灵活通用、端云结合及高性能等设计 目标的考虑。 库模式的平台层软件便于与各种既有的框架协同工作，不对软件的运行时组件添加 新的约束，应用范围也不受制约 。 除了依赖最基本的编程语言库和操作系统调用，这类平台层软 件同其他环境因素解梢，从而可以做到高度的可移植性。 在单机和终端等场景下，由于没有守护进程和调度框架的开销，有效计算逻辑的资源利用率也会提高， 进而有助于性能优化。 用户也不用担
心库模式的开发所必需的那些“脚手架” 代码，因为 TensorFlow 已经提供了多种高级抽象，尽可能地最小化了核心计算逻辑之外的开发工作 。

公共运行时实现了数据流图计算的基本逻辑 ，分布式运行时在此基础上实现了数 据流图的跨进程协同计算逻辑，算子核函数则包含图上具体操作节点的算法实现代码 。 



TensorFlow运行时核心库底层对接的是各种计算库和通信库。 这些库有的是外部组件(如用
于 CPU代数计算的 Eigen库)，有的则作为 TensorFlow源代码的一部分集成在核心库内部(如用
于 GPU并行计算的 StreamExecutor库)

Bazel Protocol  eigen cuda



读者可能会注意到， tensorflow 和 tensorflow/core 目 录下各有 一个 user_ops 目录 。 官方对二
者给出了不同的定位 :前者适用于用户以二进制包形式安装 TensorFlow 之后 ，通过 Bazel 的
t飞custom_op_lib「ary 规则构建自定义操作的情况 ; 后者适用于用户获取 TensorFlow源代码包
之后，在核 心运行 时库构~过程中编译自定义操作 的情况 。



声明式编程与命令式编程

做什么”，后者强调“怎么做”

声明式编程: 结构 化 、 抽象化，用户不必纠结每个步骤的具体实现，而是通过下定义的 方式描述期望达到的状态 。 

口命令式编程:过程化 、具体化，用户 告诉机器怎么做，机器按照用户的指示一步步执行 命令 ，并转换到最终的停止状态 。 



函数式编程{ functional
programming，简称 FP )和逻辑式编程



声明式编程: 程序是一个数学模型，输入是自变量，输出是因变量，用户设计和组合一 系列函数，通过表达式变换实现计算 。 

口命令式编程: 程序是一个有穷自动机，输入是起始状态，输出是结束状态，用户设计一 系列指令，通过指令的执行完成状态转换 。



声明式编程: 擅长基于数理逻辑的应用领域，如深度学习、人工智能、符号计算系 统等 。 

口命令式编程 :擅长复杂业务逻辑的应用领域，如交互式 UI程序 、操作系统与 实用工具软 件等。 



编程范式核心思想 实现方法 程序抽象 计算过程计算单元变 量意义擅长领域 典型应用
声明式编程 做什么 结构化、抽象化数学模型 表达式变换 函数 抽象符号数理逻辑深度学习
命令式编程 怎么做过程化 、具体化有穷自动机状态转换 指令 存储单元业务逻辑交互式四程序



引用透明 可读性强 预编译优化

无依赖逻辑并行化、 无效逻辑移除、公共逻辑提取、 细粒度操作融合等



口数学函数或表达式:比如图 3-2中的 MatMul、 BiasAdd和 s。如nax， 绝大多数节点都属于 此类。 

口存储模型参数的变量 Cva「iable):比如图 3-2中 ReLuLayer中的 Wi11 和 b。
 口占位符( placeholde「):比如图 3-2 中的 Input和 Class Labels， 它们通常用来描述输入、 

输:·I\数据的类型和形状等，便于用户利用数据的抽象结构直接定义模型。 在数据流图执 行时，占位符需要填充对应的数据 。 

后向图中的节点同样分为以下 三类 。 

口梯度值 : 即经过前向陪|计算出的模型参数 的梯度， 比如 图 3-2 中 的 Gradients。 口更新模型参数的操作: 比如图 3-2 中的 Update W和 Update b， 它们定义了如何将梯度值 

更新到对应的模型参数 。
 口更新后的模型参数: 比如图3-2中SGDTrainer内的W和lb，与前向图中的模型参数一一 

对应， 但参数值得到了更新，用于模型的下一轮训练。 



数据边 控制边



(1)以节点名称作为关键字 、 人度作为值，创建一张散列表，并将此数据流图上的所有节点放 入散列表中 。 

(2)为此数据流图创建一个可执行节点队列，将散列表中人度为 0 的节点加入到该队列，并 从散列表中删除这些节点 。 

(3)依次执行该队列中的每一个节点，执行成功后将此节点输出指向的节点的入度值减 l，更 新散列表中对应节点的人度值 。 

(4)重复步骤 (2)和步骤(3)，直到可执行节点队列变为空。 



TensorFlow 数据流图本身是一个有向无环图



TensorFlow 的张量在逻辑定义上是数据载体，但在物理实现时是一个句柄，它存储张量的元
信息以及指向张量数据的内存缓冲区指针。 这样设计是为了实现内存复用。 在某些前置操作(生
产者)的输出值被输入到多个后置操作(消费者)的情况下，无须重复存储输出值。 当一个张量
不再被任何操作依赖后， TensorFlow会释放存储该张量的内存缓冲区。例如，图3-1中的A*B和
C-D的计算结果被乘法操作处理之后，存储它们的内存将会被释放。 TensorFlow内部通过引用计
数方式判断是否应该释放张主:数据的内存缓冲区，这一机制类似于编程语言中的垃圾回收机制 。



计算节点:对应 的是无状态的计算或控制操作，主要负责算法逻辑表达或流程控制 。
口 存储节点 :对应的是有状态的变量操作，通常用来存储模型参数。
口数据节点:对应的是特殊的占位柯:操作，用于描述待输入数据的属性。



Python语言没有 内置 的接 口和抽象类 ，但可以利用异常机制抛出错误 ，
强制子类必须实现特定的属性和成员方法



口 GATE NONE : 无 同步 。 最大化并行执行效率 将梯度计算和模型参数更新过程完全并行 化。 该模式有时会导致部分计算结果无法复现。 

口 GATE_OP: 操作级同步 。 对于每个操作，分别确保所有梯度在使用之前都已计算 完成 。 当梯度计算依赖、多个输入时，这种做法能够避免计算间的竞争 。 

口 GATE_GRAPH: 图级同步 。 最小化并行执行效率，在任意梯度被使用之前，确保所有模型 参数对应的所有梯度都已经计算完成。 



(1)计算梯度 : 调用 compute_gradients 方法，依据指定的策略求得梯度值 。 

(2)处理梯度: 用户按照自己的需求处理梯度值， 如进行梯度裁剪和梯度加权。 

(3)应用梯度:调用 apply gradients 方法 ，将处理后 的梯度值应用到模型参数，实现模型 更新。 







1 创建文件名列表

2. 创建文件名队列
3. 3. 创建 Reader和 Decoder