---
layout: post
title:  机器学习学习笔记【6】
subtitle:  机器学习优化相关
date: 2017-11-19 09:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-ml6.jpg"
catalog: true
tags:
    - 机器学习
---

在使用机器学习去解决问题时，我们不仅需要掌握机器学习算法的概念，还需要掌握如何去选择这些算法以及如何去改进它们。

### 测试集与交叉验证集

我们知道，即使我们的模型能正确预测训练集中的数据，但也并不代表它是一个很好的模型，因为可能存在过拟合问题，为了检验模型是否过拟合，我们可以随机的把一部分数据作为测试集，不放入训练集中，用测试集对模型进行测试。

除了测试集，我们还可以从数据集中取一部分作为交叉验证集，来选择和调整模型。

### 偏差与方差

我们可以把误差简单的分为偏差（Bias）和方差（Variance），借用网上的图来描述它俩

![](https://github.com/VernonSong/Storage/blob/master/image/ML-VB.jpg?raw=true)

偏差大，可以理解为射击时瞄的不对，通常是模型参数过少，模型过于简单。而方差大，可以理解为射击时手乱抖，通常是模型参数过多，模型过于复杂。我们要做的是在方差与偏差之间找一个平衡点，使总体误差最小。

### 如何做针对优化

1. 获得更多的训练实例  ——解决高方差
2. 尝试减少特征的数量  ——解决高方差
3. 尝试获得更多的特征  ——解决高偏差
4. 尝试增加多项式特征  ——解决高偏差
5. 尝试减少正则化程度λ  ——解决高偏差
6. 尝试增加正则化程度λ  ——解决高方差

对于神经网络：

1. 使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算量小
2. 对于较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，计算代价较大，但可通过正则化等手段来调整。

通常从较小的神经网络开始，逐步增加隐藏层，然后选择交叉验证集代价最小的神经网络。

### 类偏斜

类偏斜（skewed classes）情况表现为我们的训练集中有许多同一种类的实例，只有很少或没有其他类的实例。

### 查准率与查全率

查准率（Precision）和查全率（Recall）将算法预测的结果分成四种情况：

1. 正确肯定（True Positive,TP）：预测为真，实际为真
2. 正确否定（True Negative,TN）：预测为假，实际为假
3. 错误肯定（False Positive,FP）：预测为真，实际为假
4. 错误否定（False Negative,FN）：预测为假，实际为真

则：
查准率=TP/(TP+FP)
查全率=TP/(TP+FN)

以预测肿瘤为例，查准率是在我们预测有恶性肿瘤的病人中，实际有恶性肿瘤的病人的百分比，越高越好。查全率为所有实际有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。

如果我们希望那个只在非常确信的情况下预测为真（恶性肿瘤），即我们希望那个更高的查准率，我们可以使用比0.5更大的阀值，如0.7。而如果希望提高查全率，尽可能让所有可能是恶性肿瘤的病人得到进一步检查，我们可以使用比0.5更小的阀值，如0.3。
