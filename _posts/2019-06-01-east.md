---
layout: post
title: 文本检测小结
subtitle: 
date: 2018-08-8 16:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-pixel-anchor.jpg"
catalog: true
mathjax: true
tags:
    - 深度学习
    - 论文翻译
---
    
## 概述
在基于深度学习的OCR领域，目前的文本检测框架主要有两类，一类是基于像素级的图像语义分割，一种是基于anchor的通用目标检测。前者往往有着更好的精度，但在小尺度文本检测上召回率偏低。后者虽然对文本尺度不敏感吗，但是精度不如基于语义分割的文本检测。同时，两种框架在面对长的中文文本行时都表现乏力。Pixel-Anchor将两种方式结合起来

## 基于图像语义分割的文本检测
基于图像语义分割的文本检测有EAST，Piexel-Link，PSENet，它们都通过FPN这样的U型网络结构来维持高空间分辨率并保留分割信息。在文本框预测阶段，
### EAST
由于之前的很多模型都将文本检测划分为多个阶段，流程复杂，且较为耗时。因此研究者提出用一种更优雅的模型结构：EAST（Efficient and Accurate Scene Text Detector）。
#### 网络结构
EAST采用了FCN这样的U型结构作为作为网络特征提取部分的框架，在下采样阶段提取特征，在上采样阶段融合特征并得到像素级的预测。

对于大的文字，其特征主要从深层的feature map中获取，小的文字特征从浅层的feature map中获取。论文中采用了1/32，1/16，1/8，1/4这四个尺度的特征，并使用PVANet作为特征提取网络。在上采样阶段，通过1*1的卷积来压缩特征，减少计算量，接着用3*3的卷积融合信息。由于整个上采样阶段的特征通道一直维持在一个较小的数量级上，因此上采样阶段的计算开销并不是很大。

在这之后是网络的输出部分，EAST包含3个输出分支，均使用1*1的卷积进行像素级的预测：

- score map：文本概率图（1 channel）
- RBOX geometry：以AABB（axis-aligned bounding box）的四条边与该像素点距离以及文本框旋转角度来表示的文本框信息（5 channel）
- QUAD geometry：以四个顶点位置与该像素点位置的偏移量来表示的文本框信息（8 channel）

#### 标签生成
在生成EAST标签时，需注意score map中positive区域面积的要比原文本框小，这样预测文本框的像素点都来自于文本框中间。论文给出的缩小文本框的方法为：

1. 将顶点坐标按顺时针排序
2. 计算每个点的最短邻边
3. 根据最短邻边长度将长对边的两个端点向内移动
4. 根据最短邻边长度将短对边的两个端点向内移动

之后，对每个positive像素，生成RBOX和QUAD两种边框标签，若数据集采用顶点坐标标注文本框，则以能覆盖此四边形的最小矩形作为RBOX目标。

#### loss计算
EAST的loss也将分为两部分

$$
L=L_s+\lambda_gL_g
$$

$L_s$为score map的classify loss，$L_g$为RBOX geometry和QUAD geometry的regression loss，论文中$\lamda$将设置为1

##### score map loss
对于score的loss计算，在很多常见的检测网络中，都需要进行正负样本的平衡和hard negative mining，这些步骤使整个训练流程变得更复杂。因此在EAST中，作者将分别用score map标签中negative和positive像素的比例作为positive和negative像素的loss权重，以此来平衡loss：

$$
\begin{align*}
&\beta=1-\frac{\sum_{y^* \in Y*} y^*}{|Y^*|} 
\newline &L_s=-\beta Y^* \mathrm{log}\hat{Y}-(1-\beta)(1-Y^*)\mathrm{log}(1-\hat{Y})
\end{align*}
$$

##### geometries loss
对于geometries loss的计算，由于文本框的大小差距很大，而常见的L1，L2 loss会导致偏差趋向更大更长的文本框，因此对于RBOX geometries的AABB部分采用效果更好的IoU loss，旋转角度采用夹角的余弦来计算loss：

$$
\begin{align*}
& L_g =L_{AABB}+\lambda _{\theta}L _{\theta}
\newline & L_{AABB}=-\mathrm{log}(\mathrm{IoU}(\mathbf{\hat{R}},\mathbf{R^*}))
\newline & L _{\theta}=1-\mathrm{cos}(\hat{\theta}-\theta ^*)
\end{align*}
$$

论文中$\lambda _{\theta}$为10。在计算IoU时，通过该像素点与每条边的距离来计算长和宽，以此得到面积，不考虑预测的旋转角度。

QUAD geometries依然使用L1 loss，但EAST中针对预测的文本框会在某一方向过长的现象，设计了一个特殊的正则项：

$$
\begin{align*}
& CQ = \{x1,y1,x2,y2, \dots ,x4,y4\}
\newline & L_g  = L_{QUAD}= \mathrm{min}\sum_{\hat{c_i} \in \hat{C{_{\mathbf{Q}}}},c_i^* \in C_{\mathbf{Q^*}}} \frac{\mathrm{smoothed}_{L_1}(\hat{c_i}-c_i^*)}{8 \times N_{\mathbf{Q^*}}}
\end{align*}

#### Locality-Aware NMS
传统的NMS，复杂度为O(n^2)，这对像素级密度预测的EAST来说速度过慢，因此EAST针对临近的geometries高度相关这一特性，先逐列逐行遍历一遍geometries，若遇到的geometries p与上一次合并后的geometries g 的IoU大于阈值，则以score为权值合并新的g，否则将p作为g。最后将局部合并后的geometries进行标准NMS计算。

### 缺点
受receptive field限制，对长文本效果不好

## 







QUAD
























### Piexel-Link

### PSENet

## 基于通用目标检测的文本检测

### CTPN


## 参考
[Pixel-Anchor: A Fast Oriented Scene Text Detector with Combined Networks](https://arxiv.org/abs/1811.07432)
[EAST: An Efficient and Accurate Scene Text Detector](https://arxiv.org/abs/1704.03155)
 
