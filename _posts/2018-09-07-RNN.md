---
layout: post
title:  RNN原理及实现
subtitle: 
date: 2018-06-27 16:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-rnn.jpg"
catalog: true
tags:
    - 深度学习
    - 论文翻译
---

## 概述
传统的前馈神经网络接受特定结构的输入，因此局限于空间上的边界，而在机器翻译，手写识别，语音识别等领域，我们往往需要处理序列数据，并结合上下文来进行预测，循环神经网络（Recurrent neural networks）就是一种能有效处理序列数据结构，它将状态在自身网络中循环传递，共享在不同位置学到的信息。RNN最早手写识别中应用，现在已广泛应用于各个领域，并延伸出了GRU，LSTM等变体。


## RNN结构

### many to many
RNN采用了一种全新的结构，它在对每一个时间步进行预测的同时将隐藏状态传递给下一个时间步
![](https://github.com/VernonSong/Storage/blob/master/image/RNN1.png?raw=true)

$h_t$是$t$时刻的隐藏状态，有

$$
\begin{align*}
&s_t=Wx_t+Uh_{t-1}+b_{\mathbf{s}}
\newline &h_t=\tanh(s_t)
\newline &\hat{y}=softmax(Vh_t+b_{\mathbf{y}})
\end{align*}
$$

对每一个时间步，我们共享上面式子中的参数的值，这类似于卷积在空间上共享权值，只是RNN是在时域上共享权值。通常情况下我们将$h_0$设为0。

```python
# -*- coding: UTF-8 -*-
import numpy as np


def softmax(x):
    max_value = np.max(x, keepdims=True)
    exp = np.exp(x - max_value)
    exp_sum = np.sum(exp, keepdims=True)
    dist = exp / exp_sum
    return dist


class RNNNumpy:
    # 此例子中x为one-hot编码，
    def __init__(self, x_dim, word_dim, hidden_dim=10, bptt_truncate=4):
        # Assign instance variables
        self.word_dim = word_dim
        self.hidden_dim = hidden_dim
        self.bptt_truncate = bptt_truncate
        # Randomly initialize the network parameters
        self.W = np.random.uniform(-np.sqrt(1. / word_dim), np.sqrt(1. / word_dim), (hidden_dim, x_dim))
        self.V = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (word_dim, hidden_dim))
        self.U = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (hidden_dim, hidden_dim))
        self.bh = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (hidden_dim))
        self.by = np.random.uniform(-np.sqrt(1. / hidden_dim), np.sqrt(1. / hidden_dim), (word_dim))

    def forward_propagation(self, x):
        # The total number of time steps
        T = len(x)
        # During forward propagation we save all hidden states in s because need them later.
        # We add one additional element for the initial hidden, which we set to 0
        h = np.zeros((T + 1, self.hidden_dim))
        h[-1] = np.zeros(self.hidden_dim)
        # The outputs at each time step. Again, we save them for later.
        o = np.zeros((T, self.word_dim))
        # For each time step...
        for t in np.arange(T):
            # Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.
            h[t] = np.tanh(self.W[:, x[t]] + self.U.dot(h[t - 1] + self.bh))
            o[t] = softmax(self.V.dot(h[t]) + self.by)
        return [o, h]
rnn = RNNNumpy(5, 4)
x = [1, 2, 3, 2, 0, 2, 4, 2]
y = [1, 0, 2, 3, 1, 3, 0, 1]
o = rnn.predict(x)
print(o)
# [[0.22159908 0.26488876 0.18158528 0.33192688]

# [0.26522228 0.14363835 0.26695782 0.32418156]

# [0.26203694 0.2313666  0.22825978 0.27833668]

# [0.2222332  0.23037303 0.21317747 0.33421631]

# [0.29493902 0.17108682 0.21605084 0.31792332]

# [0.24629964 0.18518834 0.26232996 0.30618206]

# [0.28072082 0.18565277 0.21210539 0.32152102]

# [0.23334515 0.21436683 0.24742298 0.30486504]]

```

这便是RNN的多对多（many to many）模型

### many to one与one to many
对于情感分析多对一（many to one）任务，可以只取最后一个时间步的输出。而音乐生成这类一对多（one to many）任务，只可以只输入$x_0$并指定$t$

### seq2seq
对于机器翻译这类任务，虽然输入与输出都是序列，但$y_t$与$x_t$并不严格对应，我们将这类任务成为序列到序列（Sequence to Sequence），对此我们可以使用一层多对一的RNN进行编码，一层一对多的RNN进行解码，编码层RNN最后一个时间步的隐藏状态作为解码层初始隐藏状态。
![](https://github.com/VernonSong/Storage/blob/master/image/RNN2.png?raw=true)

## loss计算
RNN的loss是每一个时间步计算loss之和。

$$
\begin{align*}
L(y,o)=-\frac{1}{N}\sum_{n \in N}y_n \mathrm{log}O_n
\end{align*}
$$

```python
# 只实现计算单个样本
def calculate_loss(self, x, y):
        L = 0
        o, s = self.forward_propagation(x)
        # We only care about our prediction of the "correct" words
        correct_word_predictions = o[np.arange(len(y)), y]
        # Add to the loss based on how off we were
        L += -1 * np.sum(np.log(correct_word_predictions))
        return L
L = rnn.calculate_loss(x, y)
print(L)
# 10.988490905048703
```

## 随时间反向传播

由于RNN的特殊的结构，反向传播的计算要稍微复杂一些，使用的算法称为随时间反向传播（BackPropagation Through Time, BPTT）

RNN损失随时间累加，计算梯度是同样要将所有时间步相加

$$
\begin{align*}
& \frac{\partial E}{\partial V}=\sum _{t=0}^T(\hat{y}_t-y_t) \otimes h_t
\newline & \frac{\partial E}{\partial b_{\mathbf{y}}}=\sum _{t=0}^T(\hat{y}_t-y_t) \
\end{align*}
$$


但对$W$，$U$和$b_{\mathbf{h}}$的求导则比较复杂$h_t$与$h_{t-1}$相关，而他们均与$W$，$U$和$b_{\mathbf{h}}$相关，根据全导数法则：

$$
\begin{align*}
\frac{\partial E}{\partial U}=\sum_{t=0}^T  \sum_{k=0}^t \frac{\partial s_k}{\partial U}\frac{\partial E_t}{\partial s_k}
\end{align*}
$$

为求$\frac{\partial E_t}{\partial s_k}$，将式子变换：

$$
\begin{align*}
& \delta _k=\frac{\partial E_t}{\partial s_k}= \frac{\partial h_k}{\partial s_k}\frac{\partial s_{k+1}}{\partial h_k}\frac{\partial E_t}{\partial s_{k+1}}=diag(1-h_k \odot h_k)U^T \delta_{k+1}=(U^T \delta _{k+1}) \odot (1-h_k \odot h_k)
\newline  &\delta _t=\frac{\partial E_t}{\partial s_t}= \frac{\partial h_t}{\partial s_t}\frac{\partial z_{t}}{\partial h_t}\frac{\partial E_t}{\partial z_{t}}=diag(1-h_t \odot h_t)V^T (\hat{y}_t-y_t)=V^T (\hat{y}_t-y_t) \odot (1-h_t \odot h_t)
\end{align*}
$$

代入$\frac{\partial E}{\partial U}$得：

$$
\begin{align*}
\frac{\partial E}{\partial U}=\sum_{t=0}^T  \sum_{k=0}^t \delta_k \otimes h_{k-1}
\end{align*}
$$

不失严谨性，定义$h_{-1}$为全0向量。

但这样的梯度计算存在缺陷，由于$\delta_k$的计算是一个累乘的过程，时间步多了之后容易出现梯度爆炸或者梯度消失，因此改进BPTT算法

$$
\begin{align*}
\frac{\partial E}{\partial U}=\sum_{t=0}^T  \sum_{k=t-l_t}^t \delta_k \otimes h_{k-1}
\end{align*}
$$

$l_t$为截断长度，通过截取固定长度的时间步，减少累乘带来的梯度爆炸和梯度消失风险，同时减少计算量。同理可得

$$
\begin{align*}
& \frac{\partial E}{\partial W}=\sum_{t=0}^T  \sum_{k=t-l_t}^t \delta_k \otimes x_k
\newline &  \frac{\partial E}{\partial b_{\mathbf{h}}} =\sum_{t=0}^T  \sum_{k=t-l_t}^t \delta_k
\end{align*}
$$

这种改进算法称为

```python
bptt(self, x, y):
        T = len(y)
        # Perform forward propagation
        o, h = self.forward_propagation(x)
        # We accumulate the gradients in these variables
        dLdU = np.zeros(self.U.shape)
        dLdV = np.zeros(self.V.shape)
        dLdW = np.zeros(self.W.shape)
        dLdbh = np.zeros(self.bh.shape)
        dLdby = np.zeros(self.by.shape)
        delta_o = o
        delta_o[np.arange(len(y)), y] -= 1.
        # For each output backwards...
        for t in np.arange(T)[::-1]:
            dLdV += np.outer(delta_o[t], h[t].T)
            dLdby += delta_o[t]
            # Initial delta calculation

            delta_t = self.V.T.dot(delta_o[t]) * (1 - (h[t] ** 2))
            # 累加时只计算bptt_truncate步
            # Backpropagation through time (for at most self.bptt_truncate steps)
            for bptt_step in np.arange(max(0, t - self.bptt_truncate), t + 1)[::-1]:
                # print "Backpropagation step t=%d bptt step=%d " % (t, bptt_step)
                dLdU += np.outer(delta_t, h[bptt_step - 1])
                dLdbh += delta_t
                dLdW[:, x[bptt_step]] += delta_t
                # Update delta for next step
                delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step - 1] ** 2)
        return [dLdU, dLdV, dLdW, dLdbh, dLdby]
```

## Tenforflow API
### tf.nn.rnn_cell.BasicRNNCell
该类定义了基本的RNN单元，其构造函数

```python
@tf_export("nn.rnn_cell.BasicRNNCell")
class BasicRNNCell(LayerRNNCell):
__init__(
    num_units,
    activation=None,
    reuse=None,
    name=None,
    dtype=None,
    **kwargs
)
```

参数：
- **num_units**：隐藏单元数目
- **activation**：激活函数，默认为tanh
- **reuse**：是否公用同scope下变量
- **name**：层名称
-  **dtype**：层默认数据类型
- **\*\*kwargs** ：其它层公用参数

此为未做性能优化版本，GPU下使用**tf.contrib.cudnn_rnn**下函数。

```python
class _CudnnRNN(base_layer.Layer):
    def __init__(self,
                 num_layers,
                 num_units,
                 input_mode=CUDNN_INPUT_LINEAR_MODE,
                 direction=CUDNN_RNN_UNIDIRECTION,
                 dropout=0.,
                 seed=None,
                 dtype=dtypes.float32,
                 kernel_initializer=None,
                 bias_initializer=None,
                 name=None):
```

Args：

- **num_layers**：RNN层数
- **num_units**：RNN隐藏单元数
- **input_mode**：是否对输入进行投影，CUDNN_INPUT_LINEAR_MODE，CUDNN_INPUT_SKIP_MODE，CUDNN_INPUT_AUTO_MODE三种模式，默认为CUDNN_INPUT_LINEAR_MODE，只有当input_size=num_units才可不进行投影
- **direction**：RNN方向，CUDNN_RNN_UNIDIRECTION为单向，CUDNN_RNN_BIDIRECTION为双向
- **dropout**：dropout比率
- **seed**：dropout随机种子
- **dtype**：层默认数据类型
- **kernel_initializer**：权重初始化值
- **bias_initializer**：偏差初始化值（默认为0）
- **name**：层名称

此类为CudnnRNNTanh，CudnnRNNRelu，CudnnGRU，CudnnLSTM的基类。


## 链接

### 参考

> [Lecture Collection | Convolutional Neural Networks for Visual Recognition (Spring 2017)](https://www.youtube.com/watch?v=6niqTuYFZLQ&index=10&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
> <br/>
> [Recurrent Neural Networks Tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
> <br/>
>[BPTT算法推导](http://www.cnblogs.com/wacc/p/5341670.html)

