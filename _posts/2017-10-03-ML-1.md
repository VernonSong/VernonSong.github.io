---
layout: post
title:  机器学习学习笔记【1】
subtitle:  机器学习相关概念
date: 2017-08-6 09:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-ml1.jpg"
catalog: true
tags:
    - 机器学习
---

## 前言

在Coursera上看到了Andrew Ng的机器学习课程，也看到网上很多人推荐，于是打算认真学习一下，希望学习完毕后能对机器学习有个初步的认识。

### 何为机器学习
机器学习(Machine Learning)这个领域，可以追溯到上世纪50年代，一位大牛编写的一个西洋棋程序。这个程序的神奇之处在于，编写程序的人并不是西洋棋高手，他的算法不是告诉程序下棋的套路，而是让程序自己去学习如何下棋，在让程序自己跟自己下了上万盘棋后，机器通过观察哪种布局更可能会赢，渐渐学会了下棋的方法。这可以说是最早的机器学习程序。而那位大牛给机器学习的定义是：在进行特定编程的情况下，给予计算机自主学习的能力。

卡内基梅隆大学的Tom Mitchell对机器学习给你出一个很数学的定义：来自一个程序被认为能从经验E中学习，解决任务 T，达到 性能度量值P，当且仅当，有了经验E后，经过P评判， 程序在处理 T 时的性能有所提升。

### 监督学习和无监督学习
监督学习(Supervised learning)和无监督学习(Unsupervised learning)是机器学习的两大类别。

其中，监督学习是从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括**回归分析**和**统计分类**。

而无监督学习的训练集没有认为标注的结果，常见的无监督学习算法有**聚类分析**。

### 代价函数和损失函数
代价函数(Cost Function)是衡量对所有样本的预测结果与实际结果的平均差距的函数，因此也叫平方误差函数，公式如下：

$$
\begin{align*}& J(\theta) = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left ( \hat{y}_{i}- y_{i} \right)^2 = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left (h_\theta (x_{i}) - y_{i} \right)^2 \end{align*}
$$

代价函数越小，就代表模型拟合的越好

这个机器学习课程中给出的损失函数(Lost Function)定义是衡量样本的预测结果与实际结果的差距的函数。但是在绝大多数情况下人们都默认损失函数跟代价函数是一个意思，不需要区分那么开。

### 梯度下降
梯度下降法(Gradient Descent)也称最速下降法。是用于找到一个函数的局部极小值的算法。其原理有点让我想到牛顿迭代法，都是通过求导，根据其导函数的性质找到所需点。公式如下：

$$
\begin{align*}& \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0,...,\theta_n) \end{align*}
$$

意思是原θj减去损失函数在当前点关于θj的导数与学习速率α的乘积即为新θj。需要注意的是梯度下降法只能求得损失函数的局部极小值，取得的是哪个极小值受起始点影响。
![](https://github.com/VernonSong/Storage/blob/master/image/ml1.png?raw=true)
像上图所示，从不同的起点，找到的路径以及最后的终点是不一样的，因此一次梯度下降后并不一定就能找到最优拟合。

学习速率α会影响每次下降的步长，其值越大，每次下降的步长越大。当α值过大时，可能会造成越过局部最小值，走到一个比值还要大的地方。造成最后的路线并非逐步下降，而是"之"字上升。而当α值过小时，下降速度会很缓慢，算法消耗时间会增加。
![](https://github.com/VernonSong/Storage/blob/master/image/ml2.png?raw=true)
看到这里的时候，就会想那如果随着下降，逐步减少α来防止越过局部最小值是不是一个好的解决办法。而事实是，根据导数的特性，本身在靠近极值点的过程中，导数就在减少，极值点的导数为0，因此我们不必担心函数会一直在极值点附近跳跃而找不到极值点。
