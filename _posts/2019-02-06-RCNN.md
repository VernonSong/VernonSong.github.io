---
layout: post
title:  目标检测网络小结
subtitle:  
date: 2018-08-31 20:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-rcnn.jpg"
catalog: true
tags:
    - 深度学习
---

## R-CNN
在R-CNN网络出现前，使用CNN进行目标检测主要有两种方法，一种是将边框的定位看做是一个回归问题，一种是使用滑动窗口检测，但两种方法效果都不好。因此，R-CNN采用了新的方法，先通过一个传统的选择性搜索（selective search）算法来获取建议区域（region proposal），然后将每个建议区域缩放至固定大小（227*227），并使用预训练的AlexNet将区域转化为4096维的特征向量。最后将特征向量送入SVM中，对其进行分类。由于这样得到的边框并不够精准，因此还需通过边框回归（Bounding Box Regression）来校准边框，提升准确度。

在训练时，R-CNN使用IoU重叠阈值来作为判断正反例的依据，由于CNN网络对小样本容易过拟合，需要在训练CNN网络时降低IoU的阈值，将那些并不精确的区域也做为正样本。而由于SVM网络对样本数不敏感，因此可以提高IoU阈值以提高准确率。在训练边框回归时同样要基于IoU，只训练大于某一IoU阈值的，因为只有这样才符合矫正边框这一目的，同时使模型接近线性，而与真实边界偏离较大的则没有矫正的必要。

## SPPNets
由于R-CNN网络需要对选择性搜索所选出的2000个候选窗口分别使用CNN来获取特征，这些计算大部分都是重复计算，使网络速度极慢。因此SPPNet提出只在整张图片上提取一次特征，然后通过空间金字塔池化（Spatial Pyramid Pooling，SPP）层，将每个建议区域的特征图转化为固定大小的特征向量。经对比，SPPnet的速度比R-CNN提升了数十倍，并且准确率与之接近。

### 空间金字塔池化层
#### 原理
空间金字塔池化是一种词袋模型（Bag-of-Words, BoW）的扩展，它将图像切分成粗糙到精细各种级别，然后整合特征。在CNN出现前，SPP一直是许多计算机视觉系统中的核心组件。SPPnet作者将SPP应用于深度CNN当中，进行多级池化，提升网络对物体变形的鲁棒性。并根据输入大小不同，动态变化池化的窗口大小和步长，使SPP的输出尺寸始终是固定的，避免了因全连接层需输入固定大小的特征而导致的图像缩放，保留了最原始的信息。

#### 实现
```python
def spatial_pyramid_pool(net,out_pooling_size):
    batch_size, h_in, w_in, feature_size = net.shape
    for i in range(len(out_pooling_size)):
        k_h = s_h = math.ceil(h_in/out_pooling_size[i][0])
        k_w = s_w = math.ceil(w_in/out_pooling_size[i][1])
        p_h = math.floor((k_h*out_pooling_size[i][0]-h_in+1)/2)
        p_w = math.floor((k_w * out_pooling_size[i][1] - w_in + 1) / 2)
        net_tmp = tf.pad(net, tf.constant([[0, 0], [0, p_h], [0, p_w], [0, 0]]))
        pooling = slim.max_pool2d(net_tmp, (k_h, k_w), stride=(s_h, s_w), padding='SAME', scope='SPP_'+str(i))
        pooling = tf.reshape(pooling, [batch_size, -1, feature_size])
        if i == 0:
            spp = pooling
        else:
            spp = tf.concat([spp, pooling], 1)
    return spp


net = np.zeros((128, 9, 7, 3), dtype=np.float32)
spatial_pyramid_pool(net, [[4, 4], [2, 2]])
```


## Fast R-CNN
虽然SPPnets极大的提升了训练和识别的速度，但它依然没有脱离R-CNN多阶段流水线式的结构，训练复杂，并且特征还需写入硬盘。除此之外，由于SPPnets反向传播难以更新SPP之前的卷积层，导致网络准确率受限。

Fast R-CNN在R-CNN的基础之上，借鉴了SPPnets的思路，对整张图片进行特征提取，并用一个单级的SPP层来将建议区域的特征图转化为固定大小。作者将这个特殊SPP层称为RoI（Region of Interest, RoI）池化层。Fast R-CNN还使用了多任务损失，将分类与边框回归合并在一起，精简了模型。

由于SPPnet是先把所有图像用选择性搜索所的到的的RoIs存起来，再从中每次一个batch的RoIs进行训练，但这一个batch的RoIs可能来自许多张图像，为了能够反向传播，需要将CNN对这些图像计算的所有数据存储起来，时间和空间上开销都比较大，网络较深时难以进行反向传播；而Fast R-CNN每次只选N张图像的RoIs生成batch，因此训练时每次只要计算和存储N张图像的在前向传播中所计算的数据，所以时间和内存开销更小。在实验中，N=2和R（batch size）=128时，达到了很好的成绩。

### 多任务损失
#### 原理
Fast R-CNN有两个输出层，一个用来进行类别预测，输出概率$p$和类别$u$；一个进行边框回归，对这两个任务进行联合训练：

$$
L(p, u, t^u, v) = L_{cls}(p, u) + \lambda[u ≥ 1]L_{loc}(t^u,v)
$$




## Faster R-CNN
Fast R-CNN还有个计算瓶颈在于选择性搜索较为耗时，未能利用GPU进行高效的计算。因此作者提出，使用CNN网络来计算推荐区域

### RPN

## 参考
> [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)
> <br/>




