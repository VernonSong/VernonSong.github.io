---
layout: post
title:  目标检测网络小结
subtitle:  
date: 2018-08-31 20:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-rcnn.jpg"
catalog: true
tags:
    - 深度学习
---

## 概述
RCNN系列网络是目标检测任务中非常常见的网络，它由最初的RCNN网络发展而来，经过不断发展和演变，诞生出了Fast R-CNN，Faster R-CNN，以及最新的用与语义分割的Mask R-CNN，不论是网络整体结构还是其中的一些想法和设计都非常值得学习。

### R-CNN
在R-CNN网络出现前，使用CNN进行目标检测主要有两种方法，一种是将边框的定位看做是一个回归问题，一种是使用滑动窗口检测，但两种方法效果都不好。因此，R-CNN采用了新的方法，先通过一个传统的选择性搜索（selective search）算法来获取建议区域（region proposal），然后将每个建议区域缩放至固定大小（227*227），并使用预训练的AlexNet将区域转化为4096维的特征向量。最后将特征向量送入SVM中，对其进行分类。由于这样得到的边框并不够精准，因此还需进行边框回归（Bounding Box Regression），得到最终边框。

在训练时，R-CNN使用IoU重叠阈值来作为判断正反例的依据，由于CNN网络对小样本容易过拟合，需要在训练CNN网络时降低IoU的阈值，将那些并不精确的区域也做为正样本。而由于SVM网络对样本数不敏感，因此可以提高IoU阈值以提高准确率。

#### 边框回归
边框回归是为了使预测的边框更为精准所设计的模块，作者采用的思路很简单，对给定边框$(P_x,P_y,P_w,P_h)$，先进行平移，然后缩放，得到最终边框$(\hat{G_x},\hat{G_y},\hat{G_w},\hat{G_h})$：

$$
\begin{align*}
& \hat{G_x}=P_wd_x(P)+P_x
\newline & \hat{G_y}=P_wd_x(P)+P_x
\newline & \hat{G_w}=P_w \mathbf{exp}(d_w(P))
\newline & \hat{G_h}=P_h \mathbf{exp}(d_h(P))
\end{align*}
$$

根据以上式子，对边框进行线性回归，损失函数为：

$$
边框回归 = 
$$



### SPPNet
由于使用AlexNet网络来生成特征向量，因此输入必须缩放至固定大小，但缩放带来的形变势必会影响到最终的准确率。而SPPNet则使用空间金字塔池化层（Spatial Pyramid Pooling）来让网络接受任意大小的输入。

SPP层的是一种词袋模型（Bag-of-Words, BoW）的扩展，它将图像切分成粗糙到精细各种级别，然后整合特征。它由一个

由于R-CNN由选择性搜索，AlexNet，SVM，边框回归这4个部分组成，因此R-CNN的训练显得十分复杂。同时多级流水线的训练过程导致需要在硬盘中存储特征数据，增大了空间开销。最关键的是，CNN部分需要对选择性搜索产生的2000张图像分别计算，但其实有很多都是重复计算。所以在训练和测试时R-CNN的检测速度都并不理想。

#### SPP层实现
```python
def spatial_pyramid_pool(net,h_out,w_out):
    _, h_in,w_in,_=net.shape
    k_h = s_h = math.ceil(h_in/h_out)
    k_w = s_w = math.ceil(w_in/w_out)
    p_h = math.floor((k_h*h_out-h_in+1)/2)
    p_w = math.floor((k_w * w_out - w_in + 1) / 2)
    net = tf.pad(net, tf.constant([[0, 0], [0, p_h], [0, p_w], [0, 0]]))
    net = slim.max_pool2d(net, (k_h, k_w), stride=(s_h, s_w), padding='SAME', scope='MaxPool_1a_3x3')
    return net
```


### Fast R-CNN
由于




