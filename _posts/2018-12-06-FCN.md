---
layout: post
title:  FCN原理与实现
subtitle: 
date: 2018-11-22 00:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-fcn.jpg"
catalog: true
mathjax: true
tags:
    - 深度学习
    - 论文翻译
---

## 概述
全卷积网络（ Fully Convolutional Networks，FCN）是一个在语义分割任务中有开创意义的网络结构，与早前Patchwise training的方式不同，该网络舍弃了全连接层，采用端到端，像素到像素的方式进行分割，并使用反卷积进行上采样。不仅在当年碾压了其它语义分割方法，还影响了之后的语义分割发展。

## 原理
### CNN语义分割
在全卷积网络出现前，使用CNN进行语义分割通常采用Patchwise training的方式，对每一个需要分类的像素，以它为中心取一个窗口作为输入，输出对这个像素的分类。然而在滑动窗口获取输入的过程中需要巨大的存储空间，并且相邻窗口的像素几乎是相同的，大部分计算都是重复的。不仅如此，这种方法在分类时所能获取的信息受窗口大小影响，较大的窗口需要更多的池化层，会降低定位精度。而较小的窗口则会无法看到更多信息，降低分类准确率。

### FCN
FCN舍弃了逐一对像素进行分类的分割方法，设计了全新的Pixelwise training方式，在传统CNN网络的下采样（subsampled）后，加入上采样（upsampling）来还原图像尺寸，达到对每个像素进行预测的效果。为此，作者从以下四方面重新设计了CNN网络。

#### 卷积化
在AlexNet 等用于分类的CNN网络中，输入是固定大小的图片，输出是类别，在网络的最后通常用全连接层产生固定大小的输出。但由于全连接层会丢弃空间信息，因此使用与该层输入等大的卷积核来替代全连接层。同时，利用滑动卷积的计算性质，使网络可以接受任意大小的图片作为输入，并在一个前向过程中完成预测，极大地提高了计算效率。

#### 反卷积
在下采样后，需要通过上采样来还原尺寸，传统的上采样方法是插值计算，但这样效果不好，作者通过反卷积来实现上采样，其前向过程就是正常卷积的反向过程。

#### skip layer
由于语义分割面临在语义和位置的内在张力问题：全局信息决定“是什么”，而局部信息决定”在哪里“。因此单纯从下采样后的全局信息还原出的图像所呈现的效果是比较差的，为了将全局信息与局部信息结合起来进行预测，作者设计了skip结构，将下采样过程中的池化层进行也反卷积，从中获取更准确的位置信息，并将其结果与从全局信息上采样的结果相结合。

## 实现

## 参考
> [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/pdf/1411.4038.pdf)