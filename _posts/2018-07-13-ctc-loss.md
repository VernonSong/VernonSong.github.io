---
layout: post
title:  CTC原理与实现
subtitle: 字符识别与语音识别神器
date: 2018-07-13 16:09:37 +08:00
author:     "VernonSong"
header-img: "img/post-bg-ctc.jpg"
catalog: true
mathjax: true
tags:
    - 深度学习
    - 论文翻译
---

## 概述
在训练语音识别模型前，将文本与语音对齐是一件很困难的事情，若是简单的设定成“每10个输入对应一个字符”，就无法应对人们说话时语速的变化。而如果人为去标定数据，又将耗费大量的时间和人力。此问题在手写字符识别中同样会出现。而CTC（Connectionist Temporal Classification）就是一种不需要将输入与输出对齐就能让网络进行训练和识别的方法。
![](https://github.com/VernonSong/Storage/blob/master/image/ctc1.png?raw=true)

## 原理与实现
由于不知道输入和输出如何对齐，CTC算法要计算所有可能的对齐方式的概率，找到最可能的对齐方式，一种最简单的方式是对每一步输入进行识别，然后合并相同类别的输出

![](https://github.com/VernonSong/Storage/blob/master/image/ctc2.png?raw=true)

但此方法存在两个问题：
1. 不是每一个输入都有对应一个输出类别，列如说话时可能会有停顿
2. 无法预测连续两个相同类别的组合，列如“HELLO”会识别为“HELO”

为解决此问题，CTC需要一个空白类
$$
\epsilon
$$
去做标记符，并限定两个连续两个相同类别之间必须用
$$
\epsilon
$$
隔开

![](https://github.com/VernonSong/Storage/blob/master/image/ctc3.png?raw=true)

使用CTC时，要满足以下两个条件：
1. X与Y单调性一致
2. X与Y呈多对一关系（Y的长度不能大于X）

### 前向后向计算
前向传播的过程可以如下图所示

![](https://github.com/VernonSong/Storage/blob/master/image/ctc5.png?raw=true)

公式表达为

$$
\begin{align*}
p(\mathbf{l} \mid \mathrm{x})=\sum_{\pi \in \mathbf{l}}\prod^T_{t=1}y_{\pi _t} ^t
\end{align*}
$$

即输入
$$
\mathrm{x}
$$
，输出序列
$$
\mathbf{l}
$$
的概率为所有转化后为
$$
\mathbf{l}
$$
的路径
$$
\pi
$$
概率之和，而路径
$$
\pi
$$
的概率为每个时间步结果为
$$
y_{\pi _t} ^t
$$
的概率的积。

**CTC经常与RNN结合在一起是因为RNN能有效结合上下文信息，若不想使用RNN，单纯将输入按相同大小进行切片也可以进行CTC计算。**

如果不做优化，暴力计算所有可能的组合的概率，计算代价将十分惊人，因此使用动态规划的思想，合并相同路径。

![](https://github.com/VernonSong/Storage/blob/master/image/FireShot%20Capture%205%20-%20Sequence%20Modeling%20with%20CTC%20-%20https___distill.pub_2017_ctc_.png?raw=true)

引入
$$
\epsilon
$$
后我们可以将Y描述为以
$$
\epsilon
$$
作为开头，结尾和字符间隔的序列

$$
\begin{align*}
Z=[\epsilon,y_1,\epsilon,y_2,...,\epsilon,y_u,\epsilon]
\end{align*}
$$

我们用
$$
\alpha_t(s)
$$
表示输入在
$$
t
$$
个时间步后为
$$
Z_{1:s}
$$
的概率，那么在最后一个时间步后的
$$
\alpha
$$
即为概率
$$
p(\mathbf{l} \mid \mathrm{x})
$$

计算
$$
\alpha_t(s)
$$
时我们会遇到两种情况

第一种情况是当
$$
z_s=\epsilon
$$
或
$$
z_s=z_{s-2}
$$
时

$$
\begin{align*}
\alpha_t(s)=(\alpha_{t-1}(s-1)+\alpha_{t-1}(s)*y_{z_s}^t 
\end{align*}
$$

其他情况下

$$
\begin{align*}
\alpha_t(s)=(\alpha_{t-2}(s-1)+(\alpha_{t-1}(s-1)+\alpha_{t-1}(s)*y_{z_s}^t
\end{align*}
$$

上述两个式子就是CTC前向计算动态规划的状态转移公式，而初始条件也显而易见

$$
\begin{align*}
&\alpha_1(1)=y_{\epsilon}^1
\newline
&\alpha_1(2)=y_{z_2}^1
\newline
&\alpha_1(s)=0,\forall s>2
\end{align*}
$$

![](https://github.com/VernonSong/Storage/blob/master/image/FireShot%20Capture%208%20-%20Sequence%20Modeling%20with%20CTC%20-%20https___distill.pub_2017_ctc_.png?raw=true)

可以看出最终的概率就是最后两个节点的
$$
\alpha
$$
之和。使用python简单实现为：

```python
import  numpy as np
def forward(y, labels):
    T, n = y.shape
    L = len(labels)
    alpha = np.zeros([T, L])

    # 初始条件
    alpha[0, 0] = y[0, labels[0]]
    alpha[0, 1] = y[0, labels[1]]
    
    # 动态规划
    for t in range(1, T):
        for i in range(L):
            s = labels[i]

            a = alpha[t - 1, i] 
            if i - 1 >= 0:
                a += alpha[t - 1, i - 1]
            if i - 2 >= 0 and s != 0 and s != labels[i - 2]:
                a += alpha[t - 1, i - 2]

            alpha[t, i] = a * y[t, s]

    return alpha
y=np.array([[0.2,0.4,0.2],
  [0.2,0.5,0.3],
  [0.2,0.2,0.6]])
labels = [0, 1, 0, 2, 0]  # 0 for blank
alpha = forward(y, labels)
print(alpha)
#[[0.2   0.4   0.    0.    0.   ]
# [0.04  0.3   0.08  0.12  0.   ]
# [0.008 0.068 0.076 0.3   0.024]]
p = alpha[-1, -1] + alpha[-1, -2]
print(p)
# 0.324
```



同时，我们把
$$
\beta_t(s)
$$
定义
$$
t
$$
个时间步后为
$$
Z_{s,|l|} 
$$
的概率，依然可以用这样的动态规划进行计算
$$
\beta_t(s)
$$
，转移方程为：

$$
\beta_t(s)=
\begin{equation}
\left\{
             \begin{array}{lr}
       (  \beta_{t-1}(s+1)+\beta_{t-1}(s))*y_{z_s}^t&  \\
\beta_{t-1}(s+2)+\beta_{t-1}(s+1)+\beta_{t-1}(s)*y_{z_s}^t&  \\
             \end{array}
\right.
\end{equation}
$$



python实现为：

```python
def backward(y, labels):
    T, V = y.shape
    L = len(labels)
    beta = np.zeros([T, L])

    # 初始条件
    beta[-1, -1] = y[-1, labels[-1]]
    beta[-1, -2] = y[-1, labels[-2]]

    for t in range(T - 2, -1, -1):
        for i in range(L):
            s = labels[i]

            a = beta[t + 1, i] 
            if i + 1 < L:
                a += beta[t + 1, i + 1]
            if i + 2 < L and s != 0 and s != labels[i + 2]:
                a += beta[t + 1, i + 2]

            beta[t, i] = a * y[t, s]

    return beta
beta = backward(y, labels)
print(beta)
# [[0.06  0.264 0.072 0.056 0.008]
# [0.    0.3   0.12  0.24  0.04 ]
# [0.    0.    0.    0.6   0.2  ]]
```

### 梯度计算

将
$$
\alpha_t(s)
$$
与
$$
\beta_t(s)
$$
相乘

$$
\begin{align*}
\alpha_t(s)\beta _t(s)&=\sum_{\pi_{1:t} \in\mathbf{l}_{1:s}}\prod_{t'=1}^ty_{ \pi_{t'}}\sum_{\pi_{t:T} \in\mathbf{l}_{s:|\mathbf{l}|}}\prod_{t'=t}^Ty_{ \pi_{t'}}
\newline & =\sum_{\substack{\pi \in \mathbf{l}} \\ \pi_t=\mathbf{l}_{s}}y_{\pi_t} ^t \prod_{t'=1}^T y_{\pi_t} ^t
\end{align*}
$$

由
$$
\begin{align*}
p(\mathbf{l} \mid \mathrm{x})=\sum_{\pi \in \mathbf{l}}\prod^T_{t=1}y_{\pi _t} ^t
\end{align*}
$$

可继续推导出

$$
\begin{align*}
p(\mathbf{l} \mid \mathrm{x})=\sum_{s=1}^{|Z|}\frac{\alpha_t(s) \beta_t(s)}{y_{z_s}^t}
\end{align*}
$$

又因为
$$
\alpha_t(s)
$$
与
$$
\beta_t(s)
$$
是关于
$$
 y_k^t
$$
的线性函数，因此可求偏导
 
$$
\begin{align*}
\frac{\partial p(\mathbf{l}\mid \mathrm{x})}{\partial y_k^t}&=\frac{\partial }{\partial y_k^t}\sum_{s \in lab(\mathbf{l},k)}\frac{\alpha y_k^t\beta y_k^t}{y_k^t}
\newline &=\sum_{s \in lab(\mathbf{l},k)}\alpha \beta
\newline &=
\frac {1}{(y^t_k)^2}\sum_{s \in lab(\mathbf{l},k)}\alpha_t(s)\beta_t(s)
\end{align*}
$$

其中
$$
s \in lab(\mathbf{l},k)
$$
表示l中所有k字符，之所以进行累加是因为虽然对路径来说，这些k在
$$
\mathbf{l}
$$
中不同位置，但它们都是在
$$
t
$$
时刻在不同路径下的映射。

一般使用对数似然函数代替最大似然函数

$$
\begin{align*}
\frac{\partial ln(p(\mathbf{l}\mid \mathrm{x}))}{\partial y_k^t}&=\frac{1 }{p(\mathbf{l}\mid \mathrm{x})}\frac{\partial p(\mathbf{l}\mid \mathrm{x})}{\partial y_k^t}
\end{align*}
$$


梯度计算的python实现：

```python
def gradient(y, labels):
    T, V = y.shape
    L = len(labels)

    alpha = forward(y, labels)
    beta = backward(y, labels)
    p = alpha[-1, -1] + alpha[-1, -2]

    grad = np.zeros([T, V])
    for t in range(T):
        for s in range(V):
            lab = [i for i, c in enumerate(labels) if c == s]
            for i in lab:
                grad[t, s] += alpha[t, i] * beta[t, i] 
            grad[t, s] /= y[t, s] ** 2

    grad /= p
    return grad

grad = gradient(y, labels)
print(grad)
# [[0.92592593 2.03703704 0.        ]
# [0.74074074 1.11111111 0.98765432]
# [0.37037037 0.         1.54320988]]
```


### 前缀束搜索
在测试阶段，求模型最可能的输出就转换成了求
$$
\begin{align*}
Y^*=\mathrm{argmax}\; p(Y \mid X)
\end{align*}
$$

常见的想法是使用贪心算法，按照当前最大的概率走

$$
\begin{align*}
A^*=\mathrm{argmax}\; \prod^T_{t=1}\; p_t(a_t \mid X)
\end{align*}
$$

但这样会漏掉一些情况，比如
$$
\lbrack a,a,\epsilon]
$$
与
$$
\lbrack a,a,a]
$$
的概率均小于
$$
\lbrack b,b,b]
$$
但由于前两个序列都映射至同一输出，实际结果为
$$
\lbrack a]
$$
的概率可能大于
$$
\lbrack b]
$$
，鉴于此，我们使用特殊的波束搜索来进行计算


常规的集束搜索在每个时间步后，选取概率最高的n条路径继续计算，n为束的大小，这样到结束时，便可以获得n个概率最大的结果。

![](https://github.com/VernonSong/Storage/blob/master/image/ctc7.png?raw=true)

将映射到同一结果的路径进行合并，取合并后概率最高的n条路径进行计算

![](https://github.com/VernonSong/Storage/blob/master/image/ctc8.png?raw=true)

这种方法称为前缀束搜索（Prefix Beam Search），需要注意的是，在前缀束搜索中，不光需要将能映射到相同序列的路径进行合并，还需要对路径进行拆分，如上图中
$$
\lbrack a,\epsilon]
$$
与
$$
\lbrack a,a]
$$
都映射为
$$
\lbrack a]
$$
，但当后一字符为
$$
a
$$
时，
$$
\lbrack a,\epsilon,a]
$$
会映射为
$$
\lbrack a,a]
$$
，而
$$
\lbrack a,a,a]
$$
依然映射为
$$
\lbrack a]
$$
。因此，在计算时我们需要同时计算和存储当前序列最后一个字符是
$$
\epsilon
$$
或非
$$
\epsilon
$$
两种情况。

```python
from collections import defaultdict
nInf = -np.float('inf')

def _logSumExp(a, b):
    '''np.log(np.exp(a) + np.exp(b))
    Args:
        a:	number
        b: 	number
    Returns:
        np.log(np.exp(a)+np.exp(b))
    '''
    # let a >= b
    if a < b:
        a, b = b, a

    if b == nInf:
        return a
    else:
        return a + np.log(1 + np.exp(b - a))

def logSumExp(*args):
    '''from scipy.special import logSumExp
    Args:
        *args:	all input arguments
    Returns:
        np.log(np.exp(arg[0])+...+np.exp(arg[n-1]))
    '''
    res = args[0]
    for e in args[1:]:
        res = _logSumExp(res, e)
    return res
def removeBlank(labels, blank=0):
    '''remove blanks and duplicate elements from labels
    Args:
        labels:	label list with 'int' elements
        black: value of blank, default is zero
    Returns:
        label list without blank
    '''
    newLabels = []

    # combine duplicate
    previous = None
    for l in labels:
        if l != previous:
            newLabels.append(l)
            previous = l

    # remove blank
    newLabels = [l for l in newLabels if l != blank]

    return newLabels
def prefixBeamDecode(y, beamSize=100, blank=0):
    T, V = y.shape
    #取log方便计算
    logY = np.log(y)
    #分以空白结尾与不以空白结尾两种
    beam = [(tuple(), (0, nInf))]	# blank, non-blank
    # beam = []	# blank, non-blank
    # # init, make sure blank path in beam
    # for i in range(V):
    # 	if i == blank:
    # 		beam.append((tuple(), (logY[0, i], nInf)))
    # 	else:
    # 		beam.append((tuple([i]), (nInf, logY[0, i])))

    for t in range(0, T):	# for every timestep
        
        newBeam = defaultdict(lambda : (nInf, nInf))
        
        for prefix, (probabilityWithBlank, probabilityNoBlank) in beam:
            for i in range(V):	# for every state
                p = logY[t, i]
                if i == blank:	# propose a blank
                    
                    newProbabilityWithBlank, newProbabilityNoBlank = newBeam[prefix]
                    # [a,blank]+[a,blank]*blank+[a]*blank
                    newProbabilityWithBlank = logSumExp(newProbabilityWithBlank, probabilityWithBlank + p, probabilityNoBlank + p)
                    newBeam[prefix] = (newProbabilityWithBlank, newProbabilityNoBlank)
                    continue
                else:	# extend with non-blank
                    #获取前一字符
                    endT = prefix[-1] if prefix else None

                    # extend current prefix
                    newPrefix = prefix + (i,)
                    newProbabilityWithBlank, newProbabilityNoBlank = newBeam[newPrefix]
                    #如果与前一个字符不等
                    if i != endT:
                        # [a,b]+[a,b,blank]*b+[a,b]*b
                        newProbabilityNoBlank = logSumExp(newProbabilityNoBlank, probabilityWithBlank + p, probabilityNoBlank + p)
                    else:
                        # [a,a]+[a,blank]*a
                        newProbabilityNoBlank = logSumExp(newProbabilityNoBlank, probabilityWithBlank + p)
                    newBeam[newPrefix] = (newProbabilityWithBlank, newProbabilityNoBlank)

                    # 当i=endT时，需重新计算newBeam[prefix]
                    # 因为[a,a]与[a]均映射为[a]
                    # 而[a,blank,a]为映射为[a,a]
                    if i == endT:
                        newProbabilityWithBlank, newProbabilityNoBlank = newBeam[prefix]
                        newProbabilityNoBlank = logSumExp(newProbabilityNoBlank, probabilityNoBlank + p)
                        newBeam[prefix] = (newProbabilityWithBlank, newProbabilityNoBlank)
                        

        # sort by the sum of probabilityWithBlank, probabilityNoBlank
        beam = sorted(newBeam.items(), key=lambda x : logSumExp(*x[1]), reverse=True)
        beam = beam[:beamSize]
    return beam
beam=prefixBeamDecode(y,3)
for string, score in beam:
        print ((removeBlank(string), np.exp(logSumExp(*score))))
# ([1, 2], 0.324)
# ([1], 0.136)
# ([2], 0.10400000000000001)
```

CTC有一重要特点便是它在计算时默认每一个时间步预测出字符为条件独立事件，这一特点的优势在于不受训练集隐含的语言环境所限制，但如果需要语言模型来辅助预测，也可以在解码时也可以将语言模型与前缀束搜索相结合。

## Tensorflow API

### tf.nn.ctc_loss
tensorflow的ctc loss函数接口为

```python
tf.nn.ctc_loss(
    labels,
    inputs,
    sequence_length,
    preprocess_collapse_repeated=False,
    ctc_merge_repeated=True,
    ignore_longer_outputs_than_inputs=False,
    time_major=True
)
```

**Args**：
- **labels**：SparseTensor（稀疏矩阵）格式编码标签
- **inputs**：CTC loss输入，该损失函数包含softmax，因此inputs不需要softmax激活
- **sequence_length**：输入序列长度
- **preprocess_collapse_repeated**：是否将标签中连续出现的相同类删除，若设为True，则标签[0,1,1,2]将转化为[0,1,2]，此参数是照顾一些做了对齐的标签，但设置后模型将无法预测重复出现的类
- **ctc_merge_repeated** ：训练时是否合并连续出现的相同类，标准CTC为True
- **ignore_longer_outputs_than_inputs**：是否忽略超过输出序列超过输入时间步的样本，若设为True则对这种样本不计算梯度，若为False则出现此情况时抛出异常
- **time_major**：输入的第一个维度是否是时间步，如果为True则输入为[max_time, batch_size, num_classes]，如果为False则输入为[batch_size, max_time, num_classes]

**Returns**：
- **ctc_loss**：CTC loss

在训练时可能会出现错误

**tensorflow/core/util/ctc/ctc_loss_calculator.cc:144] No valid path found.**

此错误是因为CTC合并重复类时，对使CTC多了一个隐含条件：**输出长度+连续重复类数量<输入长度**，即极限情况下（输出全部为相同类）：**输出长度\*2-1<输入长度**，因根据此合理设置输入长度。

### tf.nn.ctc_beam_search_decoder
tensorflow的ctc解码函数接口为
```python
tf.nn.ctc_beam_search_decoder(
    inputs,
    sequence_length,
    beam_width=100,
    top_paths=1,
    merge_repeated=True
)
```

**Args**：
- **input**：CTC decoder输入，同ctc_loss，包含softmax
- **sequence_length**：输入序列长度
- **beam_width**：束宽度，若为1则等同于贪心搜索
- **top_paths**：最佳路径数目，无法大于beam_width
- **merge_repeated**：解码时是否合并连续出现的相同类，标准CTC为True

**Returns**：
- **decoded**：一个包含SparseTensor格式top_paths的列表
- **log_probabilities**：(batch_size x top_paths)的矩阵，为top_paths的概率

## 参考
> [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](http://www.cs.toronto.edu/~graves/icml_2006.pdf)
> <br/>
>  [Sequence Modeling With CTC](https://distill.pub/2017/ctc/)
> <br/>
>  [CTC 原理及实现](https://blog.csdn.net/jackytintin/article/details/79425866)
> <br/>
>   [ctc loss中一些公式的推导](https://zhuanlan.zhihu.com/p/42137291)
>  <br/>
>  [compareCTCDecoder](https://github.com/wangershi/compareCTCDecoder)


















